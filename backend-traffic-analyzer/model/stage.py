# -*- coding: utf-8 -*-
"""stage.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KAoMUIHATYVbcCyxQgymP1aZUA-fSwYT
"""

import pandas as pd
import numpy as np
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import classification_report

# üì• Chargement du fichier CSV
df = pd.read_csv("Darknet.csv")  # Ignore les lignes corrompues
print(df.shape)
display(df.head())

# Drop unnecessary or identifier columns
drop_cols = ["Flow ID", "Src IP", "Dst IP", "Timestamp", "Label.1"]
df.drop(columns=drop_cols, errors="ignore", inplace=True)

# Drop rows with missing or infinite values
df.replace([np.inf, -np.inf], pd.NA, inplace=True)
df.dropna(inplace=True)

# Encode non-numeric features
non_numeric_cols = df.select_dtypes(include=['object']).columns.drop('Label')  # Exclude label
for col in non_numeric_cols:
    df[col] = LabelEncoder().fit_transform(df[col])

# Label encoding for multi-class target
le = LabelEncoder()
y = le.fit_transform(df["Label"])
print("Label mapping:", dict(zip(le.classes_, le.transform(le.classes_))))

# One-hot encode the label for multi-class classification
y_categorical = to_categorical(y)

# Prepare feature matrix
X = df.drop(columns=["Label"])
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_categorical, test_size=0.3, random_state=42)

# Reshape for LSTM [samples, time steps, features]
X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
X_test_lstm = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))

# Build LSTM model
model = Sequential()
model.add(LSTM(64, input_shape=(1, X_train.shape[1]), return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(32))
model.add(Dropout(0.2))
model.add(Dense(y_categorical.shape[1], activation='softmax'))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

# Train model
model.fit(X_train_lstm, y_train, epochs=10, batch_size=64, validation_data=(X_test_lstm, y_test))

# Evaluate the model

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

# Predict class probabilities
y_pred = np.argmax(model.predict(X_test_lstm), axis=1)
# Convert one-hot encoded y_test back to class indices
y_true = np.argmax(y_test, axis=1)

# Evaluate
print(confusion_matrix(y_true, y_pred))
print(classification_report(y_true, y_pred, target_names=le.classes_))

import plotly.graph_objects as go
import numpy as np
from sklearn.metrics import confusion_matrix

# Generate class labels and confusion matrix
class_labels = le.classes_  # ['Non-Tor', 'NonVPN', 'Tor', 'VPN']
cm = confusion_matrix(y_true, y_pred)

# Create heatmap
fig = go.Figure(data=go.Heatmap(
    z=cm,
    x=class_labels,
    y=class_labels,
    colorscale='Blues',
    hovertemplate='Predicted: %{x}<br>Actual: %{y}<br>Count: %{z}<extra></extra>',
    showscale=True
))

fig.update_layout(
    title='Confusion Matrix (Multi-Class LSTM)',
    xaxis_title='Predicted Label',
    yaxis_title='True Label',
    yaxis=dict(autorange='reversed')
)

fig.show()

# üì¶ Importer les biblioth√®ques n√©cessaires
from tensorflow.keras.models import save_model
import joblib
import os

# üìÅ Cr√©er un dossier "model" s'il n'existe pas
os.makedirs("model", exist_ok=True)

# üíæ Sauvegarder le mod√®le LSTM
model.save("model/traffic_classifier_model.h5")

# üíæ Sauvegarder le scaler MinMaxScaler
joblib.dump(scaler, "model/scaler.pkl")

# üíæ Sauvegarder le LabelEncoder
joblib.dump(le, "model/label_encoder.pkl")

print("‚úÖ Mod√®le, scaler et label encoder sauvegard√©s avec succ√®s dans le dossier 'model/'")